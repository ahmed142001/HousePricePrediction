# Print the MSE
paste('MSE linear regression: ',mse)
LR_model <- lm(SalePrice ~ ., data = train_data)
LR_predictions <- predict(LR_model, newdata = validation_data)
LR_model <- lm(SalePrice ~ ., data = train_data)
LR_predictions <- predict(LR_model, newdata = heldout_data)
# Calculate the root mean squared error
LR_rmse <- RMSE(heldout_data$SalePrice, LR_predictions)
paste('RMSE linear regression: ',LR_rmse)
# Calculate the mean squared error
LR_mse <- mean((heldout_data$SalePrice - LR_predictions)^2)
# Print the MSE
paste('MSE linear regression: ',LR_mse)
# Create a scatterplot
ggplot(df, aes(x = predictions, y = heldout_data$SalePrice)) +
geom_point() +
labs(x = "Predicted Values", y = "Actual Values")
# Create a data frame with your predicted values and actual values
Visualize_df <- data.frame(predicted = predictions, actual = heldout_data$SalePrice)
# Create a scatterplot
ggplot(Visualize_df, aes(x = predicted, y = actual)) +
geom_point() +
labs(x = "Predicted Values", y = "Actual Values")
library(ggplot2)
ggplot(heldout_data,aes(x=predictions,y=SalePrice))+
geom_point(size=.01 , color = "steelblue")+
geom_smooth(method = "loess", color="darkred")+
labs(x="Predicted", y="Actual")+
theme(plot.margin = unit(c(1,1,1,1), "cm"))
#Effects of ground living area on the Price of a House
ggplot(data = data, mapping = aes(x=GrLivArea, y=SalePrice))+ geom_point(colour="blue")+
geom_smooth(colour="black", method = lm, se=F, formula='y ~ x') +
labs(title = "Effects of ground living area on the Price of a House",
subtitle = "The selling price of a house increases as the ground living area widens",
x ="ground living area", y = "Sales Price" )
#Effects of Overall Quality on the Price of a House
ggplot(data = data, mapping = aes(x=OverallQual, y=SalePrice))+ geom_point(colour="blue")+
geom_smooth(colour="black", method = lm, se=F, formula='y ~ x') +
labs(title = "Effects of Overall Quality on the Price of a House",
subtitle = "The selling price of a house increases as the over quality",
x ="Overall Quality", y = "Sales Price" )
LR_model <- lm(SalePrice ~ ., data = train_data)
LR_predictions <- predict(LR_model, newdata = heldout_data)
# Create a data frame with your predicted values and actual values
Visualize_df <- data.frame(predicted = predictions, actual = heldout_data$SalePrice)
# Create a scatterplot
ggplot(Visualize_df, aes(x = predicted, y = actual)) +
geom_point() +
labs(tiltle="",x = "Predicted Values", y = "Actual Values")
LR_rmse <- RMSE(heldout_data$SalePrice, predictions)
paste('RMSE linear regression: ',LR_rmse)
# Calculate the mean squared error
LR_mse <- mean((heldout_data$SalePrice - LR_predictions)^2)
# Print the MSE
paste('MSE linear regression: ',LR_mse)
#visualizing best model predictions
# Create a data frame with your predicted values and actual values
Visualize_df <- data.frame(predicted = LR_predictions, actual = heldout_data$SalePrice)
# Create a scatterplot
ggplot(Visualize_df, aes(x = predicted, y = actual)) +
geom_point() +
labs(tiltle="",x = "Predicted Values", y = "Actual Values")
model_gbm = gbm(SalePrice ~ ., data = train_data, distribution = "gaussian", n.trees = 8000, shrinkage = .01, interaction.depth = 2)
summary(model_gbm)
predictions_gbm <- predict(model_gbm, newdata = heldout_data)
rmse <- RMSE(heldout_data$SalePrice, predictions_gbm)
paste('RMSE gbm: ',rmse)
# Calculate the mean squared error
mse <- mean((heldout_data$SalePrice - predictions_gbm)^2)
# Print the MSE
paste('MSE gbm: ',mse)
rmse_randomForest <- RMSE(heldout_data$SalePrice, predictions_randomForest)
paste('RMSE randomForest: ',rmse_randomForest)
# Calculate the mean squared error
mse_randomForest <- mean((heldout_data$SalePrice - predictions_randomForest)^2)
# Print the MSE
paste('MSE randomForest: ',mse_randomForest)
rmse_svm <- RMSE(heldout_data$SalePrice, predictions_svm)
paste('RMSE svm: ',rmse_svm)
# Calculate the mean squared error
mse_svm <- mean((heldout_data$SalePrice - predictions_svm)^2)
# Print the MSE
paste('MSE svm: ',mse_svm)
model_svm <- svm(SalePrice ~ ., data = train_data)
library(e1071)
model_svm <- svm(SalePrice ~ ., data = train_data)
predictions_svm <- predict(model_svm, newdata = heldout_data)
rmse_svm <- RMSE(heldout_data$SalePrice, predictions_svm)
paste('RMSE svm: ',rmse_svm)
# Calculate the mean squared error
mse_svm <- mean((heldout_data$SalePrice - predictions_svm)^2)
# Print the MSE
paste('MSE svm: ',mse_svm)
rmse_svm2 <- RMSE(heldout_data$SalePrice, pred)
paste('RMSE svm using gridsearch: ',rmse_svm2)
# Calculate the mean squared error
mse_svm2 <- mean((heldout_data$SalePrice - pred)^2)
# Print the MSE
paste('MSE svm using gridsearch: ',mse_svm2)
# Calculate the R-squared value
rsq <- cor(pred , heldout_data$SalePrice)^2
# Print the R-squared value
paste('R-squared value of svm using gridsearch: ',rsq)
Visualize_df <- data.frame(predicted = pred, actual = heldout_data$SalePrice)
# Create a scatterplot
ggplot(Visualize_df, aes(x = predicted, y = actual)) +
geom_point() +
labs(tiltle="",x = "Predicted Values", y = "Actual Values")
ggplot(heldout_data,aes(x=pred,y=SalePrice))+
geom_point(size=.01 , color = "steelblue")+
geom_smooth(method = "loess", color="darkred")+
labs(x="Predicted", y="Actual")+
theme(plot.margin = unit(c(1,1,1,1), "cm"))
Visualize_df <- data.frame(predicted = pred, actual = heldout_data$SalePrice)
# Create a scatterplot
ggplot(Visualize_df, aes(x = predicted, y = actual)) +
geom_point() +
labs(title ="Best Model preictions",x = "Predicted Values", y = "Actual Values")
# Create a data frame with your predicted values and actual values
Visualize_df <- data.frame(predicted = pred, actual = heldout_data$SalePrice)
# Create a scatterplot
ggplot(Visualize_df, aes(x = predicted, y = actual)) +
geom_point() +
labs(title ="Best Model predictions",x = "Predicted Values", y = "Actual Values")
#Effects of Overall Quality on the Price of a House
ggplot(data = data, mapping = aes(x=OverallQual, y=SalePrice))+ geom_point(colour="blue")+
geom_smooth(colour="black", method = lm, se=F, formula='y ~ x') +
labs(title = "Effects of Overall Quality on the Price of a House",
subtitle = "The selling price of a house increases as the over quality",
x ="Overall Quality", y = "Sales Price" )
#Effects of the square feet on the Price of a House
ggplot(data = data, mapping = aes(x=SqFt, y=SalePrice))+ geom_point(colour="blue")+
geom_smooth(colour="black", method = lm, se=F, formula='y ~ x') +
labs(title = "Effects of the square feet on the Price of a House",
subtitle = "The selling price of a house increases as the square feet increase",
x ="square feet", y = "Sales Price" )
#Effects of the YearBuilt on the Price of a House
ggplot(data = data, mapping = aes(x=YearBuilt, y=SalePrice))+ geom_point(colour="blue")+
geom_smooth(colour="black", method = lm, se=F, formula='y ~ x') +
labs(title = "Effects of the YearBuilt on the Price of a House",
subtitle = "The selling price of a house increases as the YearBuilt increase",
x ="YearBuilt", y = "Sales Price" )
dict<-list(LR=LR_rmse,RF=rmse_randomForest,GBM=rmse,SVM:rmse_svm2)
dict<-list(LR=LR_rmse,RF=rmse_randomForest,GBM=rmse,Svm:rmse_svm2)
ict<-list(LR=LR_rmse,RF=rmse_randomForest,GBM=rmse,sv:rmse_svm2)
dict<-list(LR=LR_rmse,RF=rmse_randomForest,GBM=rmse,SVM=rmse_svm2)
dict
barplot(dict, xlab = "Model", ylab = "RMSE")
dict<-list('LR'=LR_rmse,'RF'=rmse_randomForest,'GBM'=rmse,'SVM'=rmse_svm2)
dict
barplot(dict, xlab = "Model", ylab = "RMSE")
dict<-list('LR'=as.numeric(LR_rmse),'RF'=as.numeric(rmse_randomForest),'GBM'=as.numeric(rmse),'SVM'=as.numeric(rmse_svm2))
dict
# Create a bar chart
barplot(dict, xlab = "Model", ylab = "RMSE")
wordcloud(dict)
install.packages("wordcloud")
library(wordcloud)
wordcloud(dict)
install.packages("tm")
library(wordcloud)
wordcloud(dict)
plot_DF <- data.frame(keys = names(dict), values = unlist(dict))
# Create barplot
barplot(plot_DF$values, names.arg = plot_DF$keys, xlab = "Models", ylab = "RMSE")
View(train)
summary(train)
str(train)
train %>%
skimr::skim()
p_load(plotly)
tidymodels_prefer()
library(dplyr)
library(pacman)
library(tidyverse)
library(tidymodels)
library(devtools)
train %>%
skimr::skim()
sort(colSums(is.na(train)), decreasing = TRUE)
sum(is.na(test))
sum(is.na(train)) / (nrow(train) *ncol(train))
# price distribution
ggplot( train, aes( x = SalePrice)) +
geom_histogram( binwidth = 10000, color = "black", fill="white") +
geom_vline( xintercept = mean( train$SalePrice ), color = 'red' ) +
ggtitle("Price distribution") +
xlab("Sale Price") + ylab("Count") +
theme( title = element_text(size = 16),
axis.title.y = element_text(size = 11),
axis.text.y = element_text(size = 11),
axis.title.x = element_text(size = 11),
axis.text.x = element_text(size = 11),
plot.margin = margin(t = 5, r = 15, b = 5, l = 15),
plot.caption = element_text(size = 10),
aspect.ratio = 0.8)
# Create a scatter plot with a trend line
cor_coef <- cor(train$LotFrontage, train$LotArea)
plot(train$LotFrontage, train$LotArea, main = "Scatter plot with trend line", xlab = "LotFrontage", ylab = "LotArea")
abline(lm(train$LotArea ~ train$LotFrontage), col = "red")
text(x = 1, y = 9, labels = paste("Correlation Coefficient =", round(cor_coef, 2)))
# price distribution
ggplot( train, aes( x = SalePrice)) +
geom_histogram( binwidth = 10000, color = "black", fill="white") +
geom_vline( xintercept = mean( train$SalePrice ), color = 'red' ) +
ggtitle("Price distribution") +
xlab("Sale Price") + ylab("Count") +
theme( title = element_text(size = 16),
axis.title.y = element_text(size = 11),
axis.text.y = element_text(size = 11),
axis.title.x = element_text(size = 11),
axis.text.x = element_text(size = 11),
plot.margin = margin(t = 5, r = 15, b = 5, l = 15),
plot.caption = element_text(size = 10),
aspect.ratio = 0.8)
# Identify the columns with null values
null_cols <- colnames(train)[colSums(is.na(train)) > 0]
# Print the names of the columns with null values
print(null_cols)
View(Lot)
View(Lot)
train_pre %>%
skimr::skim()
print(CorHigh)
#Effects of ground living area on the Price of a House
ggplot(data = data, mapping = aes(x=GrLivArea, y=SalePrice))+ geom_point(colour="blue")+
geom_smooth(colour="black", method = lm, se=F, formula='y ~ x') +
labs(title = "Effects of ground living area on the Price of a House",
subtitle = "The selling price of a house increases as the ground living area widens",
x ="ground living area", y = "Sales Price" )
#Effects of Overall Quality on the Price of a House
ggplot(data = data, mapping = aes(x=OverallQual, y=SalePrice))+ geom_point(colour="blue")+
geom_smooth(colour="black", method = lm, se=F, formula='y ~ x') +
labs(title = "Effects of Overall Quality on the Price of a House",
subtitle = "The selling price of a house increases as the over quality",
x ="Overall Quality", y = "Sales Price" )
#Effects of the square feet on the Price of a House
ggplot(data = data, mapping = aes(x=SqFt, y=SalePrice))+ geom_point(colour="blue")+
geom_smooth(colour="black", method = lm, se=F, formula='y ~ x') +
labs(title = "Effects of the square feet on the Price of a House",
subtitle = "The selling price of a house increases as the square feet increase",
x ="square feet", y = "Sales Price" )
#visualizing best model predictions
# Create a data frame with your predicted values and actual values
Visualize_df <- data.frame(predicted = pred, actual = heldout_data$SalePrice)
# Create a scatterplot
ggplot(Visualize_df, aes(x = predicted, y = actual)) +
geom_point() +
labs(title ="Best Model predictions",x = "Predicted Values", y = "Actual Values")
library(ggplot2)
ggplot(heldout_data,aes(x=pred,y=SalePrice))+
geom_point(size=.01 , color = "steelblue")+
geom_smooth(method = "loess", color="darkred")+
labs(x="Predicted", y="Actual")+
theme(plot.margin = unit(c(1,1,1,1), "cm"))
# Create barplot
barplot(plot_DF$values, names.arg = plot_DF$keys, xlab = "Models", ylab = "RMSE")
dict
View(test)
View(train)
sprintf("The database has a total of %s columns and %s rows.", dim(train)[2], dim(train)[1])
sprintf("The test data has a total of %s columns and %s rows.", dim(test)[2], dim(test)[1])
str(train)
summary(train)
train %>%
skimr::skim()
sort(colSums(is.na(train)), decreasing = TRUE)
sum(is.na(test))
hist(train$SalePrice)
# price distribution
ggplot( train, aes( x = SalePrice)) +
geom_histogram( binwidth = 10000, color = "black", fill="white") +
geom_vline( xintercept = mean( train$SalePrice ), color = 'red' ) +
ggtitle("Price distribution") +
xlab("Sale Price") + ylab("Count") +
theme( title = element_text(size = 16),
axis.title.y = element_text(size = 11),
axis.text.y = element_text(size = 11),
axis.title.x = element_text(size = 11),
axis.text.x = element_text(size = 11),
plot.margin = margin(t = 5, r = 15, b = 5, l = 15),
plot.caption = element_text(size = 10),
aspect.ratio = 0.8)
# Create a scatter plot with a trend line
cor_coef <- cor(train$LotFrontage, train$LotArea)
plot(train$LotFrontage, train$LotArea, main = "Scatter plot with trend line", xlab = "LotFrontage", ylab = "LotArea")
abline(lm(train$LotArea ~ train$LotFrontage), col = "red")
text(x = 1, y = 9, labels = paste("Correlation Coefficient =", round(cor_coef, 2)))
# Identify the columns with null values
null_cols <- colnames(train)[colSums(is.na(train)) > 0]
# Print the names of the columns with null values
print(null_cols)
#################################
#Effects of ground living area on the Price of a House
ggplot(data = data, mapping = aes(x=GrLivArea, y=SalePrice))+ geom_point(colour="blue")+
geom_smooth(colour="black", method = lm, se=F, formula='y ~ x') +
labs(title = "Effects of ground living area on the Price of a House",
subtitle = "The selling price of a house increases as the ground living area widens",
x ="ground living area", y = "Sales Price" )
##################################
#Effects of Overall Quality on the Price of a House
ggplot(data = data, mapping = aes(x=OverallQual, y=SalePrice))+ geom_point(colour="blue")+
geom_smooth(colour="black", method = lm, se=F, formula='y ~ x') +
labs(title = "Effects of Overall Quality on the Price of a House",
subtitle = "The selling price of a house increases as the over quality",
x ="Overall Quality", y = "Sales Price" )
# Create a data frame with your predicted values and actual values
Visualize_df <- data.frame(predicted = pred, actual = heldout_data$SalePrice)
# Create a scatterplot
ggplot(Visualize_df, aes(x = predicted, y = actual)) +
geom_point() +
labs(title ="Best Model predictions",x = "Predicted Values", y = "Actual Values")
#dropping columns with huge number of missing values and unused columns
train_pre<-train %>% select(-GarageYrBlt,-Electrical,-Id,-Alley,-FireplaceQu,-PoolQC,-MiscFeature,-Fence)
View(train_pre)
test_pre<-test %>% select(-GarageYrBlt,-Electrical,-Id,-Alley,-FireplaceQu,-PoolQC,-MiscFeature,-Fence)
sort(colSums(is.na(test_pre)), decreasing = TRUE)
#combining the 2 sq ft variables into a single one
#train
train_pre <- train_pre %>% mutate(SqFt  = X1stFlrSF + X2ndFlrSF)
colnames(train_pre)
train_pre<-train_pre %>% select(-X1stFlrSF,-X2ndFlrSF)
#test
test_pre <- test_pre %>% mutate(SqFt  = X1stFlrSF + X2ndFlrSF)
colnames(test_pre)
test_pre<-test_pre %>% select(-X1stFlrSF,-X2ndFlrSF)
#Lot Frontage is highly correlated with Lot area so we use that to fill in missing values
LotArea = append(train_pre[,'LotArea'], test_pre[,'LotArea'])
LotFrontage = append(train[, 'LotFrontage'], test[, 'LotFrontage'])
Lot = data.table(LotArea, LotFrontage)
library(dplyr)
library(pacman)
library(tidyverse)
library(tidymodels)
library(devtools)
library(data.table)
library(caret)
library(gbm)
#Lot Frontage is highly correlated with Lot area so we use that to fill in missing values
LotArea = append(train_pre[,'LotArea'], test_pre[,'LotArea'])
LotFrontage = append(train[, 'LotFrontage'], test[, 'LotFrontage'])
Lot = data.table(LotArea, LotFrontage)
Frontage_model = lm(LotFrontage ~ LotArea, data = Lot)
# Identify the missing values
missing <- is.na(train_pre$LotFrontage)
missing_test <- is.na(test_pre$LotFrontage)
# Predict the missing values using the fitted model
train_pre$LotFrontage[missing] <- predict(Frontage_model, newdata = train_pre[missing, ])
test_pre$LotFrontage[missing_test] <- predict(Frontage_model, newdata = test_pre[missing_test, ])
fill_with_none= c("GarageQual", "GarageCond", "GarageFinish", "GarageType","BsmtCond", "BsmtQual", "BsmtFinType1", "BsmtFinType2", "BsmtExposure", "MasVnrType", "MSZoning", "Utilities", "KitchenQual")
#These are the missing values that are actually "None"
for (column in fill_with_none) {
train_pre[[column]][is.na(train_pre[[column]])] <- "None"
test_pre[[column]][is.na(test_pre[[column]])] <- "None"
}
############################################################
fill_with_mode=c("MasVnrType", "MSZoning", "Utilities", "Functional", "Exterior1st", "Exterior2nd", "SaleType")
#for missing categorical data we use the most common value
Mode = function(x) {
ux = unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
for (column in fill_with_mode) {
non_missing <- !is.na(train_pre[[column]])
mode_val <- Mode(train_pre[[column]][non_missing])
train_pre[[column]][is.na(train_pre[[column]])] <- mode_val
test_pre[[column]][is.na(test_pre[[column]])] <- mode_val
}
############################################################
#for missing discrete data we use the median value
filling_with_median = c("BsmtFullBath", "BsmtHalfBath", "GarageCars")
for (column in filling_with_median) {
median_val <- median(train_pre[[column]], na.rm = TRUE)
train_pre[[column]][is.na(train_pre[[column]])] <- median_val
test_pre[[column]][is.na(test_pre[[column]])] <- median_val
}
#############################################################
#for missing continuous data we use the mean value
filling_with_mean = c("MasVnrArea", "BsmtFinSF1", "BsmtFinSF2", "BsmtUnfSF", "TotalBsmtSF", "GarageArea")
for (column in filling_with_mean) {
mean_val <- mean(train[[column]], na.rm = TRUE)
train_pre[[column]][is.na(train_pre[[column]])] <- mean_val
test_pre[[column]][is.na(test_pre[[column]])] <- mean_val
}
train_pre$SalePrice <- log(train_pre$SalePrice)
#convert factors that are ratings to a numeric value
rating_col = c("GarageQual", "GarageCond", "BsmtQual", "BsmtCond", "KitchenQual", "ExterQual", "ExterCond")
scores = c("None", "Po", "Fa", "TA", "Gd", "Ex")
for (column in rating_col) {
train_pre[[column]] <- factor(train_pre[[column]], levels = scores)
train_pre[[column]] <- as.integer(train_pre[[column]])
test_pre[[column]] <- factor(test_pre[[column]], levels = scores)
test_pre[[column]] <- as.integer(test_pre[[column]])
}
unique(train$ExterQual)
unique(train_pre$ExterQual)
#############################################
library(plyr)
train_pre$LotShape<-as.integer(revalue(train_pre$LotShape, c('IR3' = 0, 'IR2' = 1, 'IR1' = 2, 'Reg' = 3)))
test_pre$LotShape<-as.integer(revalue(test_pre$LotShape, c('IR3' = 0, 'IR2' = 1, 'IR1' = 2, 'Reg' = 3)))
table(train_pre$LotShape)
#garage
Garage_F <- c('None' = 0, 'Unf' = 1, 'RFn' = 2, 'Fin' = 3)
train_pre$GarageFinish<-as.integer(revalue(train_pre$GarageFinish, Garage_F))
test_pre$GarageFinish<-as.integer(revalue(test_pre$GarageFinish, Garage_F))
table(train_pre$GarageFinish)
#basement
Bsmt_Q <- c('None' = 0, 'No' = 1, 'Mn' = 2, 'Av' = 3, 'Gd' = 4)
train_pre$BsmtExposure <- as.integer(revalue(train_pre$BsmtExposure, Bsmt_Q))
test_pre$BsmtExposure <- as.integer(revalue(test_pre$BsmtExposure, Bsmt_Q))
table(train_pre$BsmtExposure)
Bsmt_T <- c('None' = 0, 'Unf' = 1, 'LwQ' = 2, 'Rec' = 3, 'BLQ' = 4, 'ALQ' = 5, 'GLQ' = 6)
train_pre$BsmtFinType1<-as.integer(revalue(train_pre$BsmtFinType1, Bsmt_T))
test_pre$BsmtFinType1<-as.integer(revalue(test_pre$BsmtFinType1, Bsmt_T))
table(train_pre$BsmtFinType1)
train_pre$BsmtFinType2<-as.integer(revalue(train_pre$BsmtFinType2, Bsmt_T))
test_pre$BsmtFinType2<-as.integer(revalue(test_pre$BsmtFinType2, Bsmt_T))
table(train_pre$BsmtFinType2)
######################################
# Street
train_pre$Street[ train_pre$Street == 'Grvl' ] <- 0
train_pre$Street[ train_pre$Street == 'Gravel' ] <- 0
train_pre$Street[ train_pre$Street == 'Pave' ] <- 1
train_pre$Street[ train_pre$Street == 'Paved' ] <- 1
train_pre$Street<-as.integer(train_pre$Street)
test_pre$Street[ test_pre$Street == 'Grvl' ] <- 0
test_pre$Street[ test_pre$Street == 'Gravel' ] <- 0
test_pre$Street[ test_pre$Street == 'Pave' ] <- 1
test_pre$Street[ test_pre$Street == 'Paved' ] <- 1
test_pre$Street<-as.integer(test_pre$Street)
########################################
train_x<-categoricalToNumeric(train_pre)
str(train_pre$YrSold)
str(train_pre$MoSold)
train_pre$YrSold <- as.numeric(as.factor(train_pre$YrSold))
train_pre$MoSold <- as.numeric(as.factor(train_pre$MoSold))
#Corelation with sales price
library(corrplot)
numeric <- which(sapply(train_pre, is.numeric))
all_numeric <- train_pre[, numeric]
cor_numeric <- cor(all_numeric, use="pairwise.complete.obs")
sorted <- as.matrix(sort(cor_numeric[,'SalePrice'], decreasing = TRUE))
CorHigh <- names(which(apply(sorted, 1, function(x) abs(x)>0.4)))
cor_numeric <- cor_numeric[CorHigh, CorHigh]
options(repr.plot.width=50,repr.plot.height=30)
corrplot.mixed(cor_numeric, tl.col="black", tl.pos = "lt")
print(CorHigh)
data<-subset(train_pre,select = CorHigh)
summary(data)
LR_model <- lm(SalePrice ~ ., data = train_data)
LR_predictions <- predict(LR_model, newdata = heldout_data)
LR_rmse <- RMSE(heldout_data$SalePrice, predictions)
paste('RMSE linear regression: ',LR_rmse)
# Calculate the mean squared error
LR_mse <- mean((heldout_data$SalePrice - LR_predictions)^2)
# Print the MSE
paste('MSE linear regression: ',LR_mse)
model_gbm = gbm(SalePrice ~ ., data = train_data, distribution = "gaussian", n.trees = 8000, shrinkage = .01, interaction.depth = 2)
summary(model_gbm)
predictions_gbm <- predict(model_gbm, newdata = heldout_data)
rmse <- RMSE(heldout_data$SalePrice, predictions_gbm)
paste('RMSE gbm: ',rmse)
# Calculate the mean squared error
mse <- mean((heldout_data$SalePrice - predictions_gbm)^2)
# Print the MSE
paste('MSE gbm: ',mse)
library(randomForest)
model_randomForest <- randomForest(SalePrice ~ ., data = train_data)
predictions_randomForest <- predict(model_randomForest, newdata = heldout_data)
rmse_randomForest <- RMSE(heldout_data$SalePrice, predictions_randomForest)
paste('RMSE randomForest: ',rmse_randomForest)
# Calculate the mean squared error
mse_randomForest <- mean((heldout_data$SalePrice - predictions_randomForest)^2)
# Print the MSE
paste('MSE randomForest: ',mse_randomForest)
library(e1071)
model_svm <- svm(SalePrice ~ ., data = train_data)
predictions_svm <- predict(model_svm, newdata = heldout_data)
rmse_svm <- RMSE(heldout_data$SalePrice, predictions_svm)
paste('RMSE svm: ',rmse_svm)
# Calculate the mean squared error
mse_svm <- mean((heldout_data$SalePrice - predictions_svm)^2)
# Print the MSE
paste('MSE svm: ',mse_svm)
cost_range <- 10^(-2:2)
gamma_range <- 10^(-2:2)
# Perform a grid search over the hyperparameter values
best_mse <- Inf
for (cost in cost_range) {
for (gamma in gamma_range) {
model_svm2 <- svm(SalePrice ~ ., data = train_data, cost = cost, gamma = gamma)
predictions_svm <- predict(model_svm2, newdata = heldout_data)
mse <- mean((heldout_data$SalePrice - predictions_svm)^2)
if (mse < best_mse) {
best_mse <- mse
best_cost <- cost
best_gamma <- gamma
final_model<-model_svm2
}
}
}
# Print the best hyperparameters and the corresponding MSE
print(paste0("Best cost: ", best_cost, ", Best gamma: ", best_gamma))
print(paste0("Best MSE: ", best_mse))
pred<- predict(final_model, newdata = heldout_data)
print(pred)
rmse_svm2 <- RMSE(heldout_data$SalePrice, pred)
paste('RMSE svm using gridsearch: ',rmse_svm2)
# Calculate the mean squared error
mse_svm2 <- mean((heldout_data$SalePrice - pred)^2)
# Print the MSE
paste('MSE svm using gridsearch: ',mse_svm2)
